{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499a6c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp;\\ipykernel_9752\\4174935111.py:27: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  columnas = [col[\"name\"] for col in inspector.get_columns(table, schema=schema)]\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp;\\ipykernel_9752\\4174935111.py:27: SAWarning: Did not recognize type 'geography' of column 'SpatialLocation'\n",
      "  columnas = [col[\"name\"] for col in inspector.get_columns(table, schema=schema)]\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'geography' of column 'SpatialLocation'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'geography' of column 'SpatialLocation'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp;\\ipykernel_9752\\4174935111.py:27: SAWarning: Did not recognize type 'hierarchyid' of column 'DocumentNode'\n",
      "  columnas = [col[\"name\"] for col in inspector.get_columns(table, schema=schema)]\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'DocumentNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp;\\ipykernel_9752\\4174935111.py:27: SAWarning: Did not recognize type 'hierarchyid' of column 'DocumentNode'\n",
      "  columnas = [col[\"name\"] for col in inspector.get_columns(table, schema=schema)]\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'DocumentNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'geography' of column 'SpatialLocation'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'geography' of column 'SpatialLocation'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'geography' of column 'SpatialLocation'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n",
      "e:\\Universidad\\Ingenieria de Sistemas\\6 - Sexto Semestre\\Ciencia de los Datos\\Proyecto\\ETL-proyecto\\my_env\\Lib\\site-packages\\pandas\\io\\sql.py:1725: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import yaml\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), \"config.yml\")\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    config_oltp = config['OLTP']\n",
    "    config_olap = config['OLAP']\n",
    "\n",
    "url_oltp = (f\"mssql+pyodbc://{config_oltp['user']}:{config_oltp['password']}@{config_oltp['host']},{config_oltp['port']}/{config_oltp['dbname']}\"\n",
    "          f\"?driver={config_oltp['drivername'].replace(' ', '+')}\")\n",
    "\n",
    "url_olap = (f\"mssql+pyodbc://{config_olap['user']}:{config_olap['password']}@{config_olap['host']},{config_olap['port']}/{config_olap['dbname']}\"\n",
    "           f\"?driver={config_olap['drivername'].replace(' ', '+')}\")\n",
    "oltp = create_engine(url_oltp)\n",
    "olap = create_engine(url_olap)\n",
    "\n",
    "def cargaSegura(engine, schema, table):\n",
    "    inspector = inspect(engine)\n",
    "\n",
    "    # Obtener columnas\n",
    "    columnas = [col[\"name\"] for col in inspector.get_columns(table, schema=schema)]\n",
    "    columnas_problematicas = []\n",
    "\n",
    "    # Intentar cargar tabla completa\n",
    "    try:\n",
    "        return pd.read_sql_table(table_name=table, con=engine, schema=schema)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Detectar columnas problemáticas\n",
    "    for col in columnas:\n",
    "        try:\n",
    "            pd.read_sql_query(\n",
    "                f'SELECT TOP 10 \"{col}\" FROM \"{schema}\".\"{table}\"',\n",
    "                con=engine\n",
    "            )\n",
    "        except Exception:\n",
    "            columnas_problematicas.append(col)\n",
    "\n",
    "\n",
    "    # Columnas buenas\n",
    "    columnas_ok = [col for col in columnas if col not in columnas_problematicas]\n",
    "\n",
    "    # Si no hay columnas válidas\n",
    "    if not columnas_ok:\n",
    "        print(f\"⚠ La tabla {schema}.{table} no tiene columnas convertibles. Retornando dataframe vacío.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Cargar solo columnas válidas\n",
    "    query = (\n",
    "        f'SELECT {\", \".join([f\"\"\"\\\"{c}\\\"\"\"\" for c in columnas_ok])} '\n",
    "        f'FROM \"{schema}\".\"{table}\"'\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql_query(query, con=engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "def extractHumanResources(conection):\n",
    "    tablas = [\n",
    "        \"Shift\", \"Department\", \"Employee\", \"EmployeeDepartmentHistory\", \"EmployeePayHistory\"\n",
    "    ]\n",
    "    humanResources = {}\n",
    "    for tabla in tablas:\n",
    "        df = cargaSegura(conection, \"HumanResources\", tabla)\n",
    "        humanResources[tabla] = df\n",
    "        \n",
    "    return humanResources\n",
    "\n",
    "def extractPerson(conection):\n",
    "    tablas = [\n",
    "        \"PersonPhone\", \"PhoneNumberType\", \"Address\", \"AddressType\",\n",
    "        \"StateProvince\", \"BusinessEntity\", \"BusinessEntityAddress\", \"BusinessEntityContact\",\n",
    "        \"ContactType\", \"CountryRegion\", \"EmailAddress\", \"Password\", \"Person\"\n",
    "    ]\n",
    "    person = {}\n",
    "    for tabla in tablas:\n",
    "        df = cargaSegura(conection, \"Person\", tabla)\n",
    "        person[tabla] = df\n",
    "        \n",
    "    return person\n",
    "\n",
    "def extractProduction(conection):\n",
    "    tablas = [\n",
    "        \"Product\", \"ScrapReason\", \"ProductCategory\", \"ProductCostHistory\", \"ProductDescription\",\n",
    "        \"ProductDocument\", \"ProductInventory\", \"ProductListPriceHistory\", \"ProductModel\",\n",
    "        \"ProductModelIllustration\", \"ProductModelProductDescriptionCulture\", \"BillOfMaterials\",\n",
    "        \"ProductPhoto\", \"ProductProductPhoto\", \"TransactionHistory\", \"ProductReview\",\n",
    "        \"TransactionHistoryArchive\", \"ProductSubcategory\", \"UnitMeasure\", \"WorkOrder\",\n",
    "        \"Culture\", \"WorkOrderRouting\", \"Document\", \"Illustration\", \"Location\"\n",
    "    ]\n",
    "    production = {}\n",
    "    for tabla in tablas:\n",
    "        df = cargaSegura(conection, \"Production\", tabla)\n",
    "        production[tabla] = df\n",
    "        \n",
    "    return production\n",
    "\n",
    "def extractPurchasing(conection):\n",
    "    tablas = [\n",
    "        \"ShipMethod\", \"ProductVendor\", \"Vendor\", \"PurchaseOrderDetail\", \"PurchaseOrderHeader\"\n",
    "    ]\n",
    "    purchasing = {}\n",
    "    for tabla in tablas:\n",
    "        df = cargaSegura(conection, \"Purchasing\", tabla)\n",
    "        purchasing[tabla] = df\n",
    "        \n",
    "    return purchasing\n",
    "\n",
    "def extractSales(conection):\n",
    "    tablas = [\n",
    "        \"CountryRegionCurrency\", \"CreditCard\", \"Currency\", \"CurrencyRate\", \"Customer\",\n",
    "        \"PersonCreditCard\", \"SalesOrderDetail\", \"SalesOrderHeader\",\n",
    "        \"SalesOrderHeaderSalesReason\", \"SalesPerson\",\n",
    "        \"SalesPersonQuotaHistory\", \"SalesReason\", \"SalesTaxRate\",\n",
    "        \"SalesTerritory\", \"SalesTerritoryHistory\", \"ShoppingCartItem\",\n",
    "        \"SpecialOffer\", \"SpecialOfferProduct\", \"Store\"\n",
    "    ]\n",
    "    sales = {}\n",
    "    for tabla in tablas:\n",
    "        df = cargaSegura(conection, \"Sales\", tabla)\n",
    "        sales[tabla] = df\n",
    "        \n",
    "    return sales\n",
    "  \n",
    "humanResources =  extractHumanResources(oltp)\n",
    "person = extractPerson(oltp)\n",
    "production = extractProduction(oltp)\n",
    "purchasing = extractPurchasing(oltp) #Funciona\n",
    "sales = extractSales(oltp) #Funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96383b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>Name</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>AED</td>\n",
       "      <td>Emirati Dirham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CurrencyCode            Name         ModifiedDate\n",
       "count           105             105                  105\n",
       "unique          105             105                  NaN\n",
       "top             AED  Emirati Dirham                  NaN\n",
       "freq              1               1                  NaN\n",
       "mean            NaN             NaN  2008-04-30 00:00:00\n",
       "min             NaN             NaN  2008-04-30 00:00:00\n",
       "25%             NaN             NaN  2008-04-30 00:00:00\n",
       "50%             NaN             NaN  2008-04-30 00:00:00\n",
       "75%             NaN             NaN  2008-04-30 00:00:00\n",
       "max             NaN             NaN  2008-04-30 00:00:00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[\"Currency\"].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06843b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_ip(keys, base_ip=\"198.51\"):\n",
    "    ips = []\n",
    "    for k in keys:\n",
    "        # Cada \"bloque\" de 253 IPs usa el siguiente tercer octeto\n",
    "        block = (k - 1) // 253\n",
    "        last_octet = ((k - 1) % 253) + 2\n",
    "        third_octet = 100 + block  # puedes ajustar 100 a cualquier valor inicial\n",
    "        ip = f\"{base_ip}.{third_octet}.{last_octet}\"\n",
    "        ips.append(ip)\n",
    "    return ips\n",
    "\n",
    "def extraerDemografia(df, xml_col):\n",
    "    data = []\n",
    "    \n",
    "    for xml_str in df[xml_col]:\n",
    "        try:\n",
    "            root = ET.fromstring(xml_str)\n",
    "            row = {child.tag.split('}')[1]: child.text for child in root}\n",
    "            data.append(row)\n",
    "        except ET.ParseError:\n",
    "            # En caso de que haya XML mal formado\n",
    "            data.append({})\n",
    "    \n",
    "    df_parsed = pd.DataFrame(data)\n",
    "    \n",
    "    # Columnas numéricas conocidas\n",
    "    numeric_cols = [\n",
    "        'TotalPurchaseYTD', 'TotalChildren', 'NumberChildrenAtHome',\n",
    "        'NumberCarsOwned', 'HomeOwnerFlag'\n",
    "    ]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df_parsed.columns:\n",
    "            df_parsed[col] = pd.to_numeric(df_parsed[col], errors='coerce')\n",
    "    \n",
    "    # Columnas de fecha conocidas\n",
    "    date_cols = ['BirthDate', 'DateFirstPurchase']\n",
    "    \n",
    "    for col in date_cols:\n",
    "        if col in df_parsed.columns:\n",
    "            df_parsed[col] = df_parsed[col].str.replace('Z','', regex=False)  # quitar la Z\n",
    "            df_parsed[col] = pd.to_datetime(df_parsed[col], errors='coerce', format='%Y-%m-%d')\n",
    "    \n",
    "    return df_parsed\n",
    "  \n",
    "def transformDimCustomer(person, sales):\n",
    "    #Tipos IN = Individual Customer\n",
    "    dimCustomer = person[\"Person\"][person[\"Person\"][\"PersonType\"] == 'IN'].copy()\n",
    "    dimCustomer = dimCustomer.drop(columns=[\n",
    "        'PersonType', 'EmailPromotion', 'AdditionalContactInfo', 'ModifiedDate', 'rowguid'\n",
    "    ])\n",
    "    \n",
    "    demografia = extraerDemografia(dimCustomer,\"Demographics\").drop(columns=[\n",
    "        'TotalPurchaseYTD'\n",
    "    ])\n",
    "    demografia = demografia.rename(columns={\n",
    "        'Education': 'EnglishEducation',\n",
    "        'Occupation': 'EnglishOccupation',\n",
    "    })\n",
    "    \n",
    "    #Añadir español y francés\n",
    "    education_map = {\n",
    "        \"Bachelors\": {\"Spanish\": \"Licenciatura\", \"French\": \"Bac + 4\"},\n",
    "        \"Graduate Degree\": {\"Spanish\": \"Estudios de postgrado\", \"French\": \"Bac + 3\"},\n",
    "        \"High School\": {\"Spanish\": \"Educación secundaria\", \"French\": \"Bac + 2\"},\n",
    "        \"Partial College\": {\"Spanish\": \"Estudios universitarios (en curso)\", \"French\": \"Baccalauréat\"},\n",
    "        \"Partial High School\": {\"Spanish\": \"Educación secundaria (en curso)\", \"French\": \"Niveau bac\"}\n",
    "    }\n",
    "    occupation_map = {\n",
    "        \"Clerical\": {\"Spanish\": \"Administrativo\", \"French\": \"Employé\"},\n",
    "        \"Management\": {\"Spanish\": \"Gestión\", \"French\": \"Direction\"},\n",
    "        \"Manual\": {\"Spanish\": \"Obrero\", \"French\": \"Ouvrier\"},\n",
    "        \"Professional\": {\"Spanish\": \"Profesional\", \"French\": \"Cadre\"},\n",
    "        \"Skilled Manual\": {\"Spanish\": \"Obrero especializado\", \"French\": \"Technicien\"}\n",
    "    }\n",
    "    demografia[\"EnglishEducation\"] = demografia[\"EnglishEducation\"].str.strip()\n",
    "    demografia[\"EnglishOccupation\"] = demografia[\"EnglishOccupation\"].str.strip()\n",
    "\n",
    "    demografia[\"SpanishEducation\"] = demografia[\"EnglishEducation\"].map(lambda x: education_map[x][\"Spanish\"])\n",
    "    demografia[\"FrenchEducation\"] = demografia[\"EnglishEducation\"].map(lambda x: education_map[x][\"French\"])\n",
    "    \n",
    "    demografia[\"SpanishOccupation\"] = demografia[\"EnglishOccupation\"].map(lambda x: occupation_map[x][\"Spanish\"])\n",
    "    demografia[\"FrenchOccupation\"] = demografia[\"EnglishOccupation\"].map(lambda x: occupation_map[x][\"French\"])\n",
    "    \n",
    "    dimCustomer = pd.concat([dimCustomer, demografia], axis=1)\n",
    "    \n",
    "    businessEntityAddress = person[\"BusinessEntityAddress\"]\n",
    "    direccion = person[\"Address\"].drop(columns=['rowguid'])\n",
    "    customer = sales[\"Customer\"].drop(columns=['rowguid'])\n",
    "    phone = person[\"PersonPhone\"].drop(columns=['ModifiedDate', 'PhoneNumberTypeID'])\n",
    "    email = person[\"EmailAddress\"].drop(columns=['EmailAddressID', 'rowguid', 'ModifiedDate'])\n",
    "    \n",
    "    dimCustomer = dimCustomer.merge(customer[customer['PersonID'].notna()], left_on='BusinessEntityID', right_on='PersonID', how='inner').drop(columns=['PersonID'])\n",
    "    dimCustomer = dimCustomer.merge(businessEntityAddress, on='BusinessEntityID', how='left')\n",
    "    dimCustomer = dimCustomer.merge(direccion, on='AddressID', how='left')\n",
    "    dimCustomer = dimCustomer.merge(phone, on='BusinessEntityID', how='left')\n",
    "    dimCustomer = dimCustomer.merge(email, on='BusinessEntityID', how='left')\n",
    "\n",
    "    dimCustomer['CustomerKey'] = range(11000, 11000 + len(dimCustomer))\n",
    "    dimCustomer = dimCustomer.merge(\n",
    "        customer[customer['PersonID'].notna()][['PersonID', 'AccountNumber']],\n",
    "        left_on='BusinessEntityID',\n",
    "        right_on='PersonID',\n",
    "        how='left'\n",
    "    ).rename(columns={'AccountNumber_y': 'CustomerAlternateKey'})\n",
    "\n",
    "    \n",
    "    dimCustomer = dimCustomer.drop(columns=['BusinessEntityID', 'Demographics', 'CustomerID', 'StoreID', 'TerritoryID', \n",
    "       'ModifiedDate_x', 'AddressTypeID', 'PersonID',\n",
    "       'rowguid', 'ModifiedDate_y', 'AccountNumber_x',\n",
    "       'ModifiedDate',       \n",
    "    ])\n",
    "    \n",
    "    return dimCustomer\n",
    "\n",
    "def transformDimCurrency(currency):\n",
    "    dimCurrency = pd.DataFrame(columns=[\n",
    "        \"CurrencyKey\", \"CurrencyAlternateKey\", \"CurrencyName\"\n",
    "    ])\n",
    "    \n",
    "    dimCurrency[\"CurrencyAlternateKey\"] = currency[\"CurrencyCode\"] \n",
    "    dimCurrency[\"CurrencyName\"] = currency[\"Name\"] \n",
    "    dimCurrency[\"CurrencyKey\"] = range(1, len(dimCurrency) + 1)\n",
    "    \n",
    "    return dimCurrency\n",
    "\n",
    "dimCurrency = transformDimCurrency(sales[\"Currency\"])\n",
    "dimCustomer = transformDimCustomer(person, sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c54fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformDimReseller(customer, salesOrderHeader, personPhone, personAddress, personBusinessEntityAddress, demographics, dimGeography, stateProvince):\n",
    "    dimReseller = pd.DataFrame(columns=[\n",
    "        \"ResellerKey\", \"ResellerAlternateKey\", \n",
    "         \"OrderFrequency\", \"OrderMonth\", \"FirstOrderYear\", \"LastOrderYear\", \"IDStore\"\n",
    "    ])\n",
    "\n",
    "    #demographics = utils_etl.extractStoreDemographics(oltp)\n",
    "\n",
    "    # Este es para usarlo solo para sacar el CustomerID que va a SalesOrderHeader\n",
    "\n",
    "    customersNoNulos = customer[\n",
    "        customer[\"PersonID\"].notna() & customer[\"StoreID\"].notna()\n",
    "    ].copy()  \n",
    "\n",
    "    # Renombrar CustomerID a CustomerStoreID\n",
    "    customersNoNulos = customersNoNulos.rename(columns={\"CustomerID\": \"CustomerStoreID\"})\n",
    "\n",
    "    ####\n",
    "\n",
    "    customer = customer[customer[\"StoreID\"].notna()]\n",
    "\n",
    "\n",
    "    dimReseller[\"ResellerKey\"] = customer[\"CustomerID\"]\n",
    "    dimReseller[\"ResellerAlternateKey\"] = customer[\"AccountNumber\"]\n",
    "    dimReseller[\"IDStore\"] = customer[\"StoreID\"]\n",
    "\n",
    "\n",
    "    # Datos que se pueden traer desde demographics\n",
    "    dimReseller = dimReseller.merge(\n",
    "        demographics[[\"BusinessEntityID\", \"ResellerName\", \"BusinessType\", \"NumberEmployees\", \"AnnualSales\", \"BankName\", \"AnnualRevenue\", \"YearOpened\", \"ProductLine\"]],\n",
    "        left_on=\"IDStore\",\n",
    "        right_on=\"BusinessEntityID\",\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"BusinessEntityID\"])\n",
    "\n",
    "    # Teléfono\n",
    "    dimReseller = dimReseller.merge(\n",
    "        personPhone[[\"BusinessEntityID\", \"PhoneNumber\"]],\n",
    "        left_on=dimReseller[\"IDStore\"] - 1, # PersonID es StoreID - 1\n",
    "        right_on=\"BusinessEntityID\",\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"BusinessEntityID\"]) \\\n",
    "     .rename(columns={\"PhoneNumber\": \"Phone\"})\n",
    "    \n",
    "    # Direccion\n",
    "    dimReseller = dimReseller.merge(\n",
    "        personBusinessEntityAddress[[\"BusinessEntityID\", \"AddressID\"]],\n",
    "        left_on=dimReseller[\"IDStore\"],\n",
    "        right_on=\"BusinessEntityID\",\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"BusinessEntityID\"])\n",
    "\n",
    "    dimReseller = dimReseller.merge(\n",
    "        personAddress[[\"AddressID\", \"AddressLine1\", \"AddressLine2\", \"PostalCode\",  \"City\", \"StateProvinceID\"]],\n",
    "        on=\"AddressID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # GeographyKey\n",
    "    # dimReseller = dimReseller.merge(\n",
    "    #     dimGeography[[\"GeographyKey\", \"PostalCode\"]],\n",
    "    #     left_on=\"PostalCodeReseller\",\n",
    "    #     right_on=\"PostalCode\",\n",
    "    #     how=\"left\"\n",
    "    # )\n",
    "\n",
    "    dimReseller = dimReseller.merge(\n",
    "        stateProvince[[\"StateProvinceID\", \"StateProvinceCode\", \"CountryRegionCode\"]],\n",
    "        on=\"StateProvinceID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    dimReseller = dimReseller.merge(\n",
    "        dimGeography[[\"GeographyKey\", \"PostalCode\", \"City\", \"StateProvinceCode\", \"CountryRegionCode\"]],\n",
    "        on=[\"PostalCode\", \"City\", \"StateProvinceCode\", \"CountryRegionCode\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Tipo de negocio \n",
    "    codeBusiness = {\"BM\": \"Value Added Reseller\", \"BS\": \"Specialty Bike Shop\", \"OS\": \"Warehouse\"}\n",
    "    dimReseller[\"BusinessType\"] = dimReseller[\"BusinessType\"].map(codeBusiness)\n",
    "\n",
    "    # Orders\n",
    "    dimReseller = dimReseller.merge(\n",
    "        customersNoNulos[[\"CustomerStoreID\", \"StoreID\"]],\n",
    "        left_on=dimReseller[\"IDStore\"],\n",
    "        right_on=\"StoreID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    dimReseller = dimReseller.merge(\n",
    "        salesOrderHeader[[\"CustomerID\", \"OrderDate\"]],\n",
    "        left_on=dimReseller[\"CustomerStoreID\"],\n",
    "        right_on=\"CustomerID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    order_counts = dimReseller.groupby(\"CustomerStoreID\")[\"OrderDate\"].count()\n",
    "    dimReseller[\"OrderFrequency\"] = dimReseller[\"CustomerStoreID\"].map(order_counts)\n",
    "    dimReseller[\"OrderMonth\"] = dimReseller[\"OrderDate\"].dt.month\n",
    "    dimReseller[\"FirstOrderYear\"] = dimReseller.groupby(\"CustomerStoreID\")[\"OrderDate\"].transform(\"min\").dt.year\n",
    "    dimReseller[\"LastOrderYear\"]  = dimReseller.groupby(\"CustomerStoreID\")[\"OrderDate\"].transform(\"max\").dt.year\n",
    "\n",
    "    # Frecuency\n",
    "    \n",
    "    conditions = [\n",
    "    dimReseller[\"OrderFrequency\"] >= 20,\n",
    "    dimReseller[\"OrderFrequency\"] >= 10\n",
    "    ]\n",
    "\n",
    "    values = [\"A\", \"Q\"]\n",
    "\n",
    "    dimReseller[\"OrderFrequency\"] = np.select(conditions, values, default=\"S\" )\n",
    "\n",
    "\n",
    "    # Pasar las columnas a int\n",
    "    cols_int = [\"NumberEmployees\", \"YearOpened\",  \"OrderMonth\", \"FirstOrderYear\", \"LastOrderYear\"]\n",
    "\n",
    "    for c in cols_int:\n",
    "        dimReseller[c] = dimReseller[c].astype(\"Int64\")\n",
    "    \n",
    "    column_order = [\"ResellerKey\", \"GeographyKey\", \"ResellerAlternateKey\", \"Phone\", \"BusinessType\", \"ResellerName\", \n",
    "                    \"NumberEmployees\", \"OrderFrequency\", \"OrderMonth\", \"FirstOrderYear\", \"LastOrderYear\", \n",
    "                    \"ProductLine\", \"AddressLine1\", \"AddressLine2\", \"AnnualSales\", \"BankName\", \n",
    "                    \"AnnualRevenue\", \"YearOpened\"]\n",
    "    # Eliminar columnas que no están en column_order\n",
    "    for col in list(dimReseller.columns):\n",
    "        if col not in column_order:\n",
    "            dimReseller = dimReseller.drop(columns=[col])\n",
    "            \n",
    "    dimReseller = dimReseller[column_order]\n",
    "    dimReseller = dimReseller.drop_duplicates(subset=[\"ResellerKey\"])\n",
    "    \n",
    "    # DataFrame de ejemplo para unknown Reseller\n",
    "    unknown_reseller = pd.DataFrame({\n",
    "        \"ResellerKey\": [0],\n",
    "        \"GeographyKey\": [0],  # Asegúrate de tener GeographyKey=0 en DimGeography también\n",
    "        \"ResellerAlternateKey\": [\"UNKNOWN\"],\n",
    "        \"Phone\": [\"Unknown\"],\n",
    "        \"BusinessType\": [\"Unknown\"],\n",
    "        \"ResellerName\": [\"Unknown\"],\n",
    "        \"NumberEmployees\": [0],\n",
    "        \"OrderFrequency\": [\"U\"],  # U = Unknown\n",
    "        \"OrderMonth\": [0],\n",
    "        \"FirstOrderYear\": [0],\n",
    "        \"LastOrderYear\": [0],\n",
    "        \"ProductLine\": [\"Unknown\"],\n",
    "        \"AddressLine1\": [\"Unknown\"],\n",
    "        \"AddressLine2\": [\"Unknown\"],\n",
    "        \"AnnualSales\": [0.0],\n",
    "        \"BankName\": [\"Unknown\"],\n",
    "        \"AnnualRevenue\": [0.0],\n",
    "        \"YearOpened\": [0]\n",
    "    })\n",
    "\n",
    "    # Concatenar con dimReseller existente\n",
    "    dimReseller = pd.concat([dimReseller, unknown_reseller], ignore_index=True)\n",
    "\n",
    "    return dimReseller\n",
    "\n",
    "def extractStoreDemographics(engine):\n",
    "    query = \"\"\"\n",
    "    WITH XMLNAMESPACES (\n",
    "        'http://schemas.microsoft.com/sqlserver/2004/07/adventure-works/StoreSurvey' AS ss\n",
    "    )\n",
    "    SELECT \n",
    "        s.BusinessEntityID AS BusinessEntityID,\n",
    "        s.Name AS ResellerName,\n",
    "        s.SalesPersonID AS StorePersonID,\n",
    "\n",
    "        s.Demographics.value('(ss:StoreSurvey/ss:YearOpened)[1]', 'int') AS YearOpened,\n",
    "        s.Demographics.value('(ss:StoreSurvey/ss:AnnualSales)[1]', 'money') AS AnnualSales,\n",
    "        s.Demographics.value('(ss:StoreSurvey/ss:AnnualRevenue)[1]', 'money') AS AnnualRevenue,\n",
    "        s.Demographics.value('(ss:StoreSurvey/ss:NumberEmployees)[1]', 'int') AS NumberEmployees,\n",
    "        s.Demographics.value('(ss:StoreSurvey/ss:BankName)[1]', 'nvarchar(100)') AS BankName,\n",
    "        s.Demographics.value('(ss:StoreSurvey/ss:BusinessType)[1]', 'nvarchar(20)') AS BusinessType,\n",
    "        s.Demographics.value('(ss:StoreSurvey/ss:Specialty)[1]', 'nvarchar(50)') AS ProductLine\n",
    "\n",
    "    FROM Sales.Store s;\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(query, con=engine)\n",
    "\n",
    "def transformDimGeography(sales, person):\n",
    "    dimGeography = sales[\"SalesTerritory\"].drop(columns=[\n",
    "        'SalesYTD', 'CostYTD', 'CostLastYear', 'rowguid', 'ModifiedDate', 'SalesLastYear',\n",
    "        'Group', 'Name'\n",
    "    ]).drop_duplicates()\n",
    "    \n",
    "    countryNameMap = {\n",
    "        \"US\" : \"United States\", \"CA\" : \"Canada\", \"FR\" : \"France\", \"DE\" : \"Germany\",\n",
    "        \"AU\" : \"Australia\", \"GB\" : \"United Kingdom\"\n",
    "    }\n",
    "    \n",
    "    countryMap = {\"Australia\": {\"Spanish\": \"Australia\", \"French\": \"Australie\"},\n",
    "    \"Canada\": {\"Spanish\": \"Canada\", \"French\": \"Canada\"},\n",
    "    \"Germany\": {\"Spanish\": \"Alemania\", \"French\": \"Allemagne\"},\n",
    "    \"France\": {\"Spanish\": \"Francia\", \"French\": \"France\"},\n",
    "    \"United Kingdom\": {\"Spanish\": \"Reino Unido\", \"French\": \"Royaume-Uni\"},\n",
    "    \"United States\": {\"Spanish\": \"Estados Unidos\", \"French\": \"États-Unis\"}}\n",
    "    \n",
    "    dimGeography[\"EnglishCountryRegionName\"] = dimGeography[\"CountryRegionCode\"].map(lambda x: countryNameMap[x])\n",
    "    dimGeography[\"SpanishCountryRegionName\"] = dimGeography[\"EnglishCountryRegionName\"].map(lambda x: countryMap[x][\"Spanish\"])\n",
    "    dimGeography[\"FrenchCountryRegionName\"] = dimGeography[\"EnglishCountryRegionName\"].map(lambda x: countryMap[x][\"French\"])\n",
    "    \n",
    "    province = person[\"StateProvince\"].drop(columns=[\n",
    "        'CountryRegionCode', 'IsOnlyStateProvinceFlag', 'rowguid', 'ModifiedDate'\n",
    "    ]).drop_duplicates()\n",
    "    \n",
    "    dimGeography = dimGeography.merge(province, on='TerritoryID', how='right')\n",
    "    dimGeography = dimGeography.rename(columns={'Name':'StateProvinceName'})\n",
    "    \n",
    "    city = person[\"Address\"].drop(columns=[\n",
    "        'AddressID', 'AddressLine1', 'AddressLine2', 'rowguid', 'ModifiedDate'\n",
    "    ]).drop_duplicates()\n",
    "    \n",
    "    dimGeography = dimGeography.merge(city, on='StateProvinceID', how='right')\n",
    "    dimGeography = dimGeography.rename(columns={'TerritoryID':'SalesTerritoryKey'})\n",
    "    dimGeography[\"GeographyKey\"] = range(1, len(dimGeography) + 1)\n",
    "    dimGeography[\"IpAddressLocator\"] = generate_unique_ip(dimGeography[\"GeographyKey\"])\n",
    "    dimGeography = dimGeography.drop(columns=['StateProvinceID'])\n",
    "    \n",
    "    # Creamos la fila \"Unknown\"\n",
    "    unknown_geography = pd.DataFrame({\n",
    "        \"GeographyKey\": [0],\n",
    "        \"City\": [\"Unknown\"],\n",
    "        \"StateProvinceCode\": [\"UNK\"],\n",
    "        \"StateProvinceName\": [\"Unknown\"],\n",
    "        \"CountryRegionCode\": [\"UNK\"],\n",
    "        \"EnglishCountryRegionName\": [\"Unknown\"],\n",
    "        \"SpanishCountryRegionName\": [\"Unknown\"],\n",
    "        \"FrenchCountryRegionName\": [\"Unknown\"],\n",
    "        \"PostalCode\": [\"Unknown\"],\n",
    "        \"SalesTerritoryKey\": [0],  # Asegúrate de tener SalesTerritoryKey=0 en DimSalesTerritory\n",
    "        \"IpAddressLocator\": [\"Unknown\"]\n",
    "    })\n",
    "\n",
    "    # Concatenar con dimGeography existente\n",
    "    dimGeography = pd.concat([dimGeography, unknown_geography], ignore_index=True)\n",
    "\n",
    "    return dimGeography\n",
    "  \n",
    "dimGeography = transformDimGeography(sales,person)\n",
    "  \n",
    "dimReseller = transformDimReseller(\n",
    "    sales[\"Customer\"], \n",
    "    sales[\"SalesOrderHeader\"], \n",
    "    person[\"PersonPhone\"], \n",
    "    person[\"Address\"], \n",
    "    person[\"BusinessEntityAddress\"], \n",
    "    extractStoreDemographics(oltp),\n",
    "    dimGeography.copy(),\n",
    "    person[\"StateProvince\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformFactResellerSales(product, salesOrderDetail, salesOrderHeader, dimCurrency, currencyRate, dimReseller, dimEmployee):\n",
    "    salesOrderDetail = salesOrderDetail.copy()\n",
    "    salesOrderDetail[\"SalesOrderLineNumber\"] = (\n",
    "        salesOrderDetail.groupby(\"SalesOrderID\").cumcount() + 1\n",
    "    )\n",
    "\n",
    "    # Start building factResellerSales from salesOrderDetail\n",
    "    factResellerSales = salesOrderDetail[[\"ProductID\", \"SalesOrderID\", \"SpecialOfferID\", \n",
    "                                            \"SalesOrderLineNumber\", \"OrderQty\", \"UnitPrice\", \n",
    "                                            \"UnitPriceDiscount\", \"LineTotal\", \"CarrierTrackingNumber\"]].rename(\n",
    "        columns={\"ProductID\": \"ProductKey\"}\n",
    "    )\n",
    "\n",
    "\n",
    "    # Now merge with salesOrderHeader\n",
    "    factResellerSales = factResellerSales.merge(\n",
    "        salesOrderHeader[[\"SalesOrderID\", \"SalesOrderNumber\", \"RevisionNumber\", \"OrderDate\", \n",
    "                            \"DueDate\", \"ShipDate\", \"CustomerID\", \"TerritoryID\", \n",
    "                            \"Freight\", \"CurrencyRateID\", \"TaxAmt\"]],\n",
    "        on=\"SalesOrderID\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\n",
    "        \"SpecialOfferID\": \"PromotionKey\", \n",
    "        \"OrderQty\": \"OrderQuantity\", \n",
    "        \"UnitPriceDiscount\": \"UnitPriceDiscountPct\", \n",
    "        \"TerritoryID\": \"SalesTerritoryKey\", \n",
    "        \"LineTotal\": \"SalesAmount\"\n",
    "    }).drop(columns=[\"SalesOrderID\"])\n",
    "\n",
    "    \n",
    "    factResellerSales = factResellerSales.merge(\n",
    "        dimReseller[[\"ResellerKey\", \"ResellerAlternateKey\"]],\n",
    "        left_on=\"CustomerID\",\n",
    "        right_on=\"ResellerKey\",\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"CustomerID\"])\n",
    "\n",
    "\n",
    "    factResellerSales = factResellerSales.merge(\n",
    "        product[[\"ProductID\", \"StandardCost\"]],\n",
    "        left_on=\"ProductKey\",\n",
    "        right_on=\"ProductID\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"StandardCost\": \"ProductStandardCost\"}) \\\n",
    "    .drop(columns=[\"ProductID\"])\n",
    "    \n",
    "    factResellerSales = factResellerSales.merge(\n",
    "        currencyRate[[\"CurrencyRateID\", \"ToCurrencyCode\"]],\n",
    "        on=\"CurrencyRateID\",\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"CurrencyRateID\"]).merge(\n",
    "        dimCurrency[[\"CurrencyAlternateKey\", \"CurrencyKey\"]],\n",
    "        left_on=\"ToCurrencyCode\",\n",
    "        right_on=\"CurrencyAlternateKey\",\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"CurrencyAlternateKey\", \"ToCurrencyCode\"])\n",
    "\n",
    "    factResellerSales = factResellerSales.merge(\n",
    "        dimEmployee[[\"EmployeeKey\", \"EmployeeNationalIDAlternateKey\"]],\n",
    "        left_on=\"SalesPersonID\",    # columna en fact table\n",
    "        right_on=\"EmployeeNationalIDAlternateKey\",  # columna en dimEmployee\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"EmployeeNationalIDAlternateKey\"])\n",
    "\n",
    "\n",
    "    def transforma_date(date):\n",
    "        if pd.isna(date):\n",
    "            return None\n",
    "        return int(date.strftime(\"%Y%m%d\"))\n",
    "    \n",
    "    factResellerSales[\"OrderDateKey\"] = factResellerSales[\"OrderDate\"].apply(transforma_date).astype(\"Int64\")\n",
    "    factResellerSales[\"DueDateKey\"] = factResellerSales[\"DueDate\"].apply(transforma_date).astype(\"Int64\")\n",
    "    factResellerSales[\"ShipDateKey\"] = factResellerSales[\"ShipDate\"].apply(transforma_date).astype(\"Int64\")\n",
    "    \n",
    "    factResellerSales[\"ExtendedAmount\"] = factResellerSales[\"UnitPrice\"] * factResellerSales[\"OrderQuantity\"]\n",
    "    factResellerSales[\"DiscountAmount\"] = factResellerSales[\"ExtendedAmount\"] * factResellerSales[\"UnitPriceDiscountPct\"]\n",
    "    factResellerSales[\"TotalProductCost\"] = factResellerSales[\"ProductStandardCost\"] * factResellerSales[\"OrderQuantity\"]\n",
    "\n",
    "    factResellerSales[\"CurrencyKey\"] = factResellerSales[\"CurrencyKey\"].fillna(0).astype(int)\n",
    "    factResellerSales[\"ResellerKey\"] = factResellerSales[\"ResellerKey\"].fillna(0).astype(int)\n",
    "\n",
    "    column_order = [\"ProductKey\", \"OrderDateKey\", \"DueDateKey\", \"ShipDateKey\", \"ResellerKey\", \"EmployeeKey\", \"PromotionKey\", \"CurrencyKey\",\n",
    "        \"SalesTerritoryKey\", \"SalesOrderNumber\", \"SalesOrderLineNumber\", \"RevisionNumber\", \"OrderQuantity\", \n",
    "        \"UnitPrice\", \"ExtendedAmount\", \"UnitPriceDiscountPct\", \"DiscountAmount\", \"ProductStandardCost\", \"TotalProductCost\",\n",
    "        \"SalesAmount\", \"TaxAmt\", \"Freight\", \"CarrierTrackingNumber\", \"OrderDate\", \"DueDate\", \"ShipDate\"]\n",
    "    \n",
    "    factResellerSales = factResellerSales[column_order]\n",
    "    \n",
    "    return factResellerSales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe76860",
   "metadata": {},
   "outputs": [],
   "source": [
    "factResellerSales = transformFactResellerSales(        \n",
    "    production[\"Product\"], \n",
    "    sales[\"SalesOrderDetail\"], \n",
    "    sales[\"SalesOrderHeader\"], \n",
    "    dimCurrency.copy(), \n",
    "    sales[\"CurrencyRate\"], \n",
    "    dimReseller.copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff4f2457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ProductKey', 'OrderDateKey', 'DueDateKey', 'ShipDateKey',\n",
      "       'PromotionKey', 'CurrencyKey', 'SalesTerritoryKey', 'SalesOrderNumber',\n",
      "       'SalesOrderLineNumber', 'RevisionNumber', 'OrderQuantity', 'UnitPrice',\n",
      "       'ExtendedAmount', 'UnitPriceDiscountPct', 'DiscountAmount',\n",
      "       'ProductStandardCost', 'TotalProductCost', 'SalesAmount', 'TaxAmt',\n",
      "       'Freight', 'CarrierTrackingNumber', 'OrderDate', 'DueDate', 'ShipDate'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProductKey               0\n",
       "OrderDateKey             0\n",
       "DueDateKey               0\n",
       "ShipDateKey              0\n",
       "PromotionKey             0\n",
       "CurrencyKey              0\n",
       "SalesTerritoryKey        0\n",
       "SalesOrderNumber         0\n",
       "SalesOrderLineNumber     0\n",
       "RevisionNumber           0\n",
       "OrderQuantity            0\n",
       "UnitPrice                0\n",
       "ExtendedAmount           0\n",
       "UnitPriceDiscountPct     0\n",
       "DiscountAmount           0\n",
       "ProductStandardCost      0\n",
       "TotalProductCost         0\n",
       "SalesAmount              0\n",
       "TaxAmt                   0\n",
       "Freight                  0\n",
       "CarrierTrackingNumber    0\n",
       "OrderDate                0\n",
       "DueDate                  0\n",
       "ShipDate                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Todo hasta freight debe ser not null\n",
    "#Tiene NaN CustomerKey, CurrencyKey, TaxAmt\n",
    "print(factResellerSales.columns)\n",
    "factResellerSales.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebb9b61e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'factInternetSales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Filas donde CustomerKey es NaN\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m nan_customers = \u001b[43mfactInternetSales\u001b[49m[factInternetSales[\u001b[33m\"\u001b[39m\u001b[33mCustomerKey\u001b[39m\u001b[33m\"\u001b[39m].isna()]\n\u001b[32m      3\u001b[39m no_nan_customers = factInternetSales[factInternetSales[\u001b[33m\"\u001b[39m\u001b[33mCustomerKey\u001b[39m\u001b[33m\"\u001b[39m].notna()]\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal filas con CustomerKey NaN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(nan_customers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'factInternetSales' is not defined"
     ]
    }
   ],
   "source": [
    "# Filas donde CustomerKey es NaN\n",
    "nan_customers = factInternetSales[factInternetSales[\"CustomerKey\"].isna()]\n",
    "no_nan_customers = factInternetSales[factInternetSales[\"CustomerKey\"].notna()]\n",
    "\n",
    "print(f\"Total filas con CustomerKey NaN: {len(nan_customers)}\")\n",
    "print(f\"Total filas sin CustomerKey NaN: {len(no_nan_customers)}\")\n",
    "\n",
    "# Número de CustomerID únicos en salesOrderHeader\n",
    "num_unique_customerID = sales[\"SalesOrderHeader\"][\"CustomerID\"].nunique()\n",
    "print(f\"CustomerID únicos en salesOrderHeader: {num_unique_customerID}\")\n",
    "\n",
    "# Número de filas en customer\n",
    "num_rows_customer = len(dimCustomer)\n",
    "print(f\"Filas totales en customer: {num_rows_customer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
